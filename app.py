#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
æ™ºèƒ½é—®ç­”ç³»ç»Ÿæ ¸å¿ƒæ¨¡å— - å®Œæ•´å¢å¼ºç‰ˆ
åŠŸèƒ½ï¼šæ–‡æœ¬åˆ†ç±»ã€æƒ…æ„Ÿåˆ†æã€æœºå™¨ç¿»è¯‘ã€æ™ºèƒ½é—®ç­” + 7ä¸ªæ–°å¢æ–‡æœ¬åˆ†æåŠŸèƒ½ + å›¾ç‰‡åŠŸèƒ½
æ–°å¢ï¼šæ–‡æœ¬ç»Ÿè®¡ã€æ–‡æœ¬æ‘˜è¦ã€è¯é¢‘åˆ†æã€è¯­è¨€æ£€æµ‹ã€å…³é”®è¯æå–ã€å‘½åå®ä½“è¯†åˆ«ã€æ·±åº¦æ€è€ƒã€ç”Ÿæˆå›¾ç‰‡ã€æ·»åŠ å›¾ç‰‡
âœ… æ‰€æœ‰åŠŸèƒ½åªè¦å¼€å¯å°±æ˜¾ç¤ºï¼Œä¸å—æ–‡æœ¬é•¿åº¦é™åˆ¶
"""

import os
import json
import re
import sys
import http.client
import warnings
import base64
import time
from io import BytesIO
from PIL import Image
import requests
from typing import Tuple, Dict, Optional
from flask import Flask, request, jsonify, render_template

# å¯¼å…¥ç«å±±å¼•æ“æ–¹èˆŸSDKï¼ˆå›¾ç‰‡ç”Ÿæˆæ ¸å¿ƒä¾èµ–ï¼‰
from volcenginesdkarkruntime import Ark

# ç¦ç”¨TensorFlowè­¦å‘Š
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'
warnings.filterwarnings('ignore')

# å¯¼å…¥æ–°å¢æ¨¡å—
try:
    from text_analysis_modules import (
        analyze_text_statistics,
        analyze_text_summary,
        analyze_word_frequency,
        analyze_language,
        analyze_keywords,
        analyze_entities,
        analyze_deep_thinking
    )
    NEW_MODULES_AVAILABLE = True
except ImportError:
    print("âš ï¸ æ–°å¢æ–‡æœ¬åˆ†ææ¨¡å—æœªæ‰¾åˆ°ï¼Œéƒ¨åˆ†åŠŸèƒ½å°†ä¸å¯ç”¨")
    NEW_MODULES_AVAILABLE = False

# ========== é…ç½®å¸¸é‡ ==========
class Config:
    """ç³»ç»Ÿé…ç½®ç±»"""
    ARK_API_HOST = "ark.cn-beijing.volces.com"
    ARK_API_PATH = "/api/v3/chat/completions"
    ARK_AUTH_TOKEN = "Bearer 7ee197bf-ebd0-482c-931c-f3bae5e3a5ec"
    ARK_MODEL = "doubao-seed-1-6-251015"
    
    # å›¾ç‰‡åŠŸèƒ½é…ç½®ï¼ˆç›´æ¥å¡«å†™API Keyï¼Œæ— éœ€ç¯å¢ƒå˜é‡ï¼‰
    ARK_IMAGE_API_KEY = "ä½ çš„ç«å±±å¼•æ“API Key"  # ğŸ‘‰ å¿…é¡»æ›¿æ¢ä¸ºå®é™…API Key
    IMAGE_UPLOAD_DIR = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'static/uploaded_images')

    @staticmethod
    def get_model_paths() -> Dict[str, str]:
        """è·å–æ¨¡å‹è·¯å¾„é…ç½®"""
        base_dir = os.path.dirname(os.path.abspath(__file__))
        return {
            'text_category_model': os.path.join(base_dir, '../tmp/text_category_model.h5'),
            'sentiment_model': os.path.join(base_dir, '../tmp/sentiment_model.h5'),
            'sentiment_dicts': os.path.join(base_dir, '../tmp/sentiment_dicts.csv'),
            'vocab_dir': os.path.join(base_dir, '../data/cnews.vocab.txt')
        }

    @staticmethod
    def init_image_dir():
        """åˆå§‹åŒ–å›¾ç‰‡ä¸Šä¼ ç›®å½•"""
        if not os.path.exists(Config.IMAGE_UPLOAD_DIR):
            os.makedirs(Config.IMAGE_UPLOAD_DIR)

# ========== å…¨å±€çŠ¶æ€ ==========
class SystemState:
    """ç³»ç»ŸçŠ¶æ€ç®¡ç†å™¨"""
    _instance = None

    def __new__(cls):
        if cls._instance is None:
            cls._instance = super().__new__(cls)
            cls._instance._sentiment_dicts = None
            cls._instance._sentiment_model = None
            cls._instance._translation_loaded = False
            cls._instance._text_classification_available = False
            cls._instance._enabled_models = {
                'text_classification': True,
                'sentiment_analysis': True,
                'translation': True,
                'qa': True,
                'text_statistics': True,
                'text_summary': True,
                'word_frequency': True,
                'language_detection': True,
                'keyword_extraction': True,
                'entity_recognition': True,
                'deep_thinking': True,
                'image_generate': True,  # ç”Ÿæˆå›¾ç‰‡åŠŸèƒ½å¼€å…³
                'image_upload': True      # æ·»åŠ å›¾ç‰‡åŠŸèƒ½å¼€å…³
            }
        return cls._instance

    @property
    def translation_loaded(self) -> bool:
        return self._translation_loaded

    @translation_loaded.setter
    def translation_loaded(self, value: bool):
        self._translation_loaded = value

    @property
    def text_classification_available(self) -> bool:
        return self._text_classification_available

    @text_classification_available.setter
    def text_classification_available(self, value: bool):
        self._text_classification_available = value

    def is_model_enabled(self, model_name: str) -> bool:
        """æ£€æŸ¥æ¨¡å‹æ˜¯å¦å¯ç”¨"""
        return self._enabled_models.get(model_name, False)

    def set_model_state(self, model_name: str, enabled: bool):
        """è®¾ç½®æ¨¡å‹çŠ¶æ€"""
        if model_name in self._enabled_models:
            self._enabled_models[model_name] = enabled
            return True
        return False

# ========== æ–‡æœ¬å¤„ç†å·¥å…· ==========
class TextProcessor:
    """æ–‡æœ¬å¤„ç†å·¥å…·ç±»"""

    CONTROL_CHARS = re.compile(r'[\x00-\x08\x0B\x0C\x0E-\x1F\x7F]')
    PUNCT_MAP = {
        ',': 'ï¼Œ', '.': 'ã€‚', '?': 'ï¼Ÿ', '!': 'ï¼',
        ':': 'ï¼š', ';': 'ï¼›', '(': 'ï¼ˆ', ')': 'ï¼‰',
        '[': 'ã€', ']': 'ã€‘'
    }
    END_PUNCTS = 'ã€‚ï¼ï¼Ÿï¼›ï¼Œ'

    @classmethod
    def sanitize_text(cls, text: str) -> str:
        """æ¸…ç†æ–‡æœ¬ä¸­çš„éæ³•å­—ç¬¦"""
        if not text:
            return ""
        return cls.CONTROL_CHARS.sub(' ', text).strip()

    @classmethod
    def format_text(cls, text: str) -> str:
        """æ ¼å¼åŒ–æ–‡æœ¬ï¼ˆæ ‡ç‚¹è½¬æ¢ã€Markdownå¤„ç†ç­‰ï¼‰"""
        if not text:
            return ""

        text = cls.sanitize_text(text)

        try:
            text = json.loads(f'"{text}"')
        except:
            pass

        text = text.replace('\n', '<br>').replace('ã€€', ' ')
        text = re.sub(r'[\u200b\u200c\u200d\r]', '', text)

        # MarkdownåŠ ç²—å¤„ç†
        text = re.sub(r'\*\*(.*?)\*\*', r'<b>\1</b>', text)

        # æ ‡ç‚¹è½¬æ¢
        for en, cn in cls.PUNCT_MAP.items():
            text = text.replace(en, cn)

        # æ•°å­—ä¸­çš„ç‚¹å·æ¢å¤
        text = re.sub(r'(\d+)ã€‚(\d+)', r'\1.\2', text)
        text = re.sub(r'(\d+\.\d+)ã€‚(\d+)', r'\1.\2', text)

        return text

# ========== å›¾ç‰‡å¤„ç†å·¥å…·ç±» ==========
class ImageProcessor:
    """å›¾ç‰‡å¤„ç†å·¥å…·ç±»ï¼ˆé›†æˆç«å±±å¼•æ“SDKï¼‰"""
    @staticmethod
    def generate_image(prompt: str) -> str:
        """ç›´æ¥è°ƒç”¨ç«å±±å¼•æ“SDKç”Ÿæˆå›¾ç‰‡ï¼ˆä¿®å¤å‚æ•°å’Œé”™è¯¯å¤„ç†ï¼‰"""
        try:
            # éªŒè¯API Keyæ˜¯å¦å¡«å†™
            if not Config.ARK_IMAGE_API_KEY or Config.ARK_IMAGE_API_KEY == "ä½ çš„ç«å±±å¼•æ“API Key":
                print("âŒ é”™è¯¯ï¼šè¯·åœ¨Configç±»ä¸­å¡«å†™çœŸå®çš„ARK_IMAGE_API_KEY")
                return ""

            # åˆå§‹åŒ–Arkå®¢æˆ·ç«¯
            client = Ark(
                base_url="https://ark.cn-beijing.volces.com/api/v3",
                api_key=Config.ARK_IMAGE_API_KEY
            )

            # ä¿®å¤ï¼šæ·»åŠ å¿…å¡«å‚æ•°nï¼ŒæŒ‡å®šç”Ÿæˆå›¾ç‰‡æ•°é‡ï¼ˆç«å±±SDKå¿…å¡«ï¼‰
            imagesResponse = client.images.generate(
                model="doubao-seedream-4-5-251128",  # ç¡®è®¤è¯¥æ¨¡å‹å·²å¼€é€š
                prompt=prompt,
                n=1,  # æ–°å¢å¿…å¡«å‚æ•°ï¼šç”Ÿæˆ1å¼ å›¾ç‰‡
                sequential_image_generation="disabled",
                response_format="url",
                size="1024x1024",  # é™ä½åˆ†è¾¨ç‡ï¼ŒåŠ å¿«ç”Ÿæˆé€Ÿåº¦ï¼Œå‡å°‘å¤±è´¥æ¦‚ç‡
                stream=False,
                watermark=True  # å…è´¹ç‰ˆå¿…é¡»å¯ç”¨æ°´å°
            )

            # ä¸‹è½½å›¾ç‰‡å¹¶ä¿å­˜åˆ°æœ¬åœ°ï¼ˆæ·»åŠ è¶…æ—¶é‡è¯•ï¼‰
            try:
                image_url = imagesResponse.data[0].url
                # ä¿®å¤ï¼šæ·»åŠ User-Agentï¼Œé¿å…è¢«æ‹’ç»è®¿é—®
                headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'}
                image_data = requests.get(image_url, headers=headers, timeout=30).content
            except requests.exceptions.RequestException as e:
                print(f"âŒ å›¾ç‰‡ä¸‹è½½å¤±è´¥ï¼š{str(e)}")
                return ""
            
            # ç”Ÿæˆå”¯ä¸€æ–‡ä»¶åï¼ˆé¿å…å†²çªï¼‰
            img_name = f"generated_{int(time.time())}.png"
            img_path = os.path.join(Config.IMAGE_UPLOAD_DIR, img_name)
            
            with open(img_path, 'wb') as f:
                f.write(image_data)
            
            # è¿”å›å‰ç«¯å¯è®¿é—®çš„ç›¸å¯¹è·¯å¾„
            return f"static/uploaded_images/{img_name}"
        
        except ImportError:
            print("âŒ é”™è¯¯ï¼šæœªå®‰è£…ç«å±±å¼•æ“SDK")
            print("ğŸ‘‰ è¯·æ‰§è¡Œï¼špip install 'volcengine-python-sdk[ark]' -i https://pypi.tuna.tsinghua.edu.cn/simple")
            return ""
        except Exception as e:
            # è¯¦ç»†è¾“å‡ºé”™è¯¯ä¿¡æ¯ï¼Œæ–¹ä¾¿æ’æŸ¥
            print(f"âŒ å›¾ç‰‡ç”Ÿæˆå®Œæ•´é”™è¯¯ï¼š{str(e)}")
            # å¸¸è§é”™è¯¯æç¤º
            if "Invalid API key" in str(e):
                print("ğŸ‘‰ æç¤ºï¼šAPI Keyæ— æ•ˆï¼Œè¯·æ£€æŸ¥æ˜¯å¦å¡«å†™æ­£ç¡®")
            elif "permission" in str(e).lower():
                print("ğŸ‘‰ æç¤ºï¼šæƒé™ä¸è¶³ï¼Œè¯·å¼€é€šdoubao-seedream-4-5-251128æ¨¡å‹æƒé™")
            elif "quota" in str(e).lower():
                print("ğŸ‘‰ æç¤ºï¼šå…è´¹é¢åº¦å·²ç”¨å®Œï¼Œè¯·å……å€¼æˆ–æ›´æ¢è´¦å·")
            return ""

    @staticmethod
    def upload_image(file_data: str, filename: str) -> str:
        """å¤„ç†ä¸Šä¼ çš„æœ¬åœ°å›¾ç‰‡ï¼ˆä¿®å¤base64è§£ç å…¼å®¹ï¼‰"""
        try:
            # ä¿®å¤ï¼šå…¼å®¹ä¸åŒæ ¼å¼çš„base64æ•°æ®
            if 'base64,' in file_data:
                base64_data = file_data.split('base64,')[-1]
            else:
                base64_data = file_data
            
            img_data = base64.b64decode(base64_data)
            img = Image.open(BytesIO(img_data))
            
            # ä¿®å¤ï¼šç»Ÿä¸€ä¿å­˜ä¸ºPNGæ ¼å¼ï¼Œé¿å…æ ¼å¼å…¼å®¹é—®é¢˜
            img_name = f"uploaded_{int(time.time())}.png"
            img_path = os.path.join(Config.IMAGE_UPLOAD_DIR, img_name)
            img.save(img_path, format='PNG')
            
            # è¿”å›å‰ç«¯å¯è®¿é—®è·¯å¾„
            return f"static/uploaded_images/{img_name}"
        except Exception as e:
            print(f"âŒ å›¾ç‰‡ä¸Šä¼ å¤±è´¥ï¼š{str(e)}")
            return ""

# ========== æ¨¡å‹ç®¡ç†å™¨ ==========
class ModelManager:
    """æ¨¡å‹åŠ è½½å’Œç®¡ç†ç±»"""

    @staticmethod
    def initialize_models() -> None:
        """åˆå§‹åŒ–æ‰€æœ‰æ¨¡å‹"""
        state = SystemState()
        paths = Config.get_model_paths()

        print("=" * 50)
        print("æ™ºèƒ½é—®ç­”ç³»ç»Ÿåˆå§‹åŒ–ä¸­...")
        print("=" * 50)

        state.text_classification_available = ModelManager._check_text_classification_model(
            paths['text_category_model']
        )

        ModelManager._load_sentiment_model(
            paths['sentiment_model'],
            paths['sentiment_dicts']
        )

        ModelManager._load_translation_model()
        
        if NEW_MODULES_AVAILABLE:
            print("âœ“ æ–‡æœ¬åˆ†ææ‰©å±•æ¨¡å—å·²åŠ è½½ï¼ˆ7ä¸ªæ–°åŠŸèƒ½ï¼‰")
        else:
            print("âœ— æ–‡æœ¬åˆ†ææ‰©å±•æ¨¡å—æœªåŠ è½½")
        
        # åˆå§‹åŒ–å›¾ç‰‡ç›®å½•
        Config.init_image_dir()
        print("âœ“ å›¾ç‰‡åŠŸèƒ½ç›®å½•å·²åˆå§‹åŒ–")

        print("=" * 50)
        print("ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆï¼")
        print("=" * 50)

    @staticmethod
    def _check_text_classification_model(model_path: str) -> bool:
        if os.path.exists(model_path):
            print("âœ“ æ–‡æœ¬åˆ†ç±»æ¨¡å‹å·²å°±ç»ª")
            return True
        else:
            print("âœ— æ–‡æœ¬åˆ†ç±»æ¨¡å‹ä¸å­˜åœ¨ï¼ˆåŠŸèƒ½å°†è¢«ç¦ç”¨ï¼‰")
            return False

    @staticmethod
    def _load_sentiment_model(model_path: str, dicts_path: str) -> None:
        state = SystemState()
        if os.path.exists(model_path):
            try:
                from emotion_analysis import load_sentiment_deps
                state._sentiment_dicts, state._sentiment_model = load_sentiment_deps(
                    model_path, dicts_path)
                if state._sentiment_dicts is not None:
                    print("âœ“ æƒ…æ„Ÿåˆ†ææ¨¡å‹åŠ è½½æˆåŠŸ")
                else:
                    print("âœ— æƒ…æ„Ÿåˆ†ææ¨¡å‹åŠ è½½å¤±è´¥")
            except Exception as e:
                print(f"âœ— æƒ…æ„Ÿåˆ†ææ¨¡å‹åŠ è½½é”™è¯¯: {str(e)}")
        else:
            print("âœ— æƒ…æ„Ÿåˆ†ææ¨¡å‹ä¸å­˜åœ¨ï¼ˆåŠŸèƒ½å°†è¢«ç¦ç”¨ï¼‰")

    @staticmethod
    def _load_translation_model() -> None:
        state = SystemState()
        try:
            from machine_translation import load_translation_model
            load_translation_model()
            state.translation_loaded = True
            print("âœ“ æœºå™¨ç¿»è¯‘æ¨¡å‹åŠ è½½æˆåŠŸ")
        except Exception as e:
            state.translation_loaded = False
            print(f"âœ— æœºå™¨ç¿»è¯‘æ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}")

# ========== æ ¸å¿ƒèŠå¤©æœåŠ¡ ==========
class ChatService:
    """æ™ºèƒ½é—®ç­”æœåŠ¡æ ¸å¿ƒç±»"""

    SENTIMENT_PROMPTS = {
        "positive": "ç”¨æˆ·æƒ…ç»ªç§¯æï¼Œè¯·ä¿æŒçƒ­æƒ…å›å¤ï¼›",
        "negative": "ç”¨æˆ·æƒ…ç»ªæ¶ˆæï¼Œè¯·å…ˆå®‰æŠšå†è§£ç­”ï¼›",
        "neutral": "ç”¨æˆ·æƒ…ç»ªä¸­æ€§ï¼Œè¯·ç®€æ´ä¸“ä¸šåœ°å›å¤ï¼›"
    }

    TRANSLATION_PATTERN = re.compile(
        r'ä¸­è¯‘è‹±[:ï¼š]?\s*(.+?)($|ï¼›|ã€‚|ï¼Œ|ï¼|ï¼Ÿ)|ç¿»è¯‘[:ï¼š]?\s*(.+?)($|ï¼›|ã€‚|ï¼Œ|ï¼|ï¼Ÿ)',
        re.IGNORECASE
    )

    # å›¾ç‰‡ç”ŸæˆæŒ‡ä»¤åŒ¹é…ï¼ˆæ”¯æŒ"ç”Ÿæˆå›¾ç‰‡ï¼šå…³é”®è¯"æ ¼å¼ï¼‰
    IMAGE_GENERATE_PATTERN = re.compile(r'ç”Ÿæˆå›¾ç‰‡[:ï¼š]?\s*(.+?)($|ï¼›|ã€‚|ï¼Œ|ï¼|ï¼Ÿ)', re.IGNORECASE)

    @classmethod
    def process_message(cls, sentence: str, enabled_models: Dict[str, bool]) -> str:
        """å¤„ç†ç”¨æˆ·æ¶ˆæ¯ - æ‰€æœ‰å¯ç”¨çš„åŠŸèƒ½è‡ªåŠ¨æ˜¾ç¤º"""
        try:
            # æ”¶é›†æ‰€æœ‰åˆ†æç»“æœ
            analysis_results = []
            
            # 1. æ–‡æœ¬åˆ†ç±»ï¼ˆåŸæœ‰åŠŸèƒ½ï¼‰
            category, cat_score = "æœªçŸ¥", 0.0
            if enabled_models.get('text_classification', True):
                category, cat_score = cls._classify_text(sentence)

            # 2. æƒ…æ„Ÿåˆ†æï¼ˆåŸæœ‰åŠŸèƒ½ï¼‰
            sentiment, sent_score = "neutral", 0.5
            if enabled_models.get('sentiment_analysis', True):
                sentiment, sent_score = cls._analyze_sentiment(sentence)
            
            # 3. 7å¤§æ–‡æœ¬åˆ†æåŠŸèƒ½ï¼ˆåŸæœ‰æ–°å¢ï¼‰
            if NEW_MODULES_AVAILABLE:
                if enabled_models.get('text_statistics', True):
                    try:
                        analysis_results.append(analyze_text_statistics(sentence))
                    except Exception as e:
                        print(f"æ–‡æœ¬ç»Ÿè®¡é”™è¯¯: {e}")
                if enabled_models.get('language_detection', True):
                    try:
                        analysis_results.append(analyze_language(sentence))
                    except Exception as e:
                        print(f"è¯­è¨€æ£€æµ‹é”™è¯¯: {e}")
                if enabled_models.get('keyword_extraction', True):
                    try:
                        analysis_results.append(analyze_keywords(sentence, top_n=5))
                    except Exception as e:
                        print(f"å…³é”®è¯æå–é”™è¯¯: {e}")
                if enabled_models.get('word_frequency', True):
                    try:
                        analysis_results.append(analyze_word_frequency(sentence, top_n=8))
                    except Exception as e:
                        print(f"è¯é¢‘åˆ†æé”™è¯¯: {e}")
                if enabled_models.get('text_summary', True):
                    try:
                        analysis_results.append(analyze_text_summary(sentence, max_sentences=2))
                    except Exception as e:
                        print(f"æ–‡æœ¬æ‘˜è¦é”™è¯¯: {e}")
                if enabled_models.get('entity_recognition', True):
                    try:
                        analysis_results.append(analyze_entities(sentence))
                    except Exception as e:
                        print(f"å®ä½“è¯†åˆ«é”™è¯¯: {e}")
                if enabled_models.get('deep_thinking', True):
                    try:
                        analysis_results.append(analyze_deep_thinking(sentence))
                    except Exception as e:
                        print(f"æ·±åº¦æ€è€ƒé”™è¯¯: {e}")

            # 4. å›¾ç‰‡ç”Ÿæˆå¤„ç†ï¼ˆæ–°å¢æ ¸å¿ƒåŠŸèƒ½ï¼‰
            if enabled_models.get('image_generate', True):
                image_match = cls.IMAGE_GENERATE_PATTERN.search(sentence)
                if image_match:
                    prompt = image_match.group(1).strip()
                    if prompt:
                        image_path = ImageProcessor.generate_image(prompt)
                        if image_path:
                            # ç”Ÿæˆå›¾ç‰‡æˆåŠŸï¼Œè¿”å›ç»“æœ+åˆ†æä¿¡æ¯
                            image_result = f"""ğŸ–¼ï¸ <b>å›¾ç‰‡ç”Ÿæˆç»“æœ</b>
<br>â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
<br>ğŸ“ ç”Ÿæˆæç¤ºè¯ï¼š{prompt}
<br><img src="{image_path}" style="max-width:300px;border-radius:8px;margin-top:8px;">"""
                            if analysis_results:
                                image_result += "<br><br>â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”<br><b>ã€æ‰©å±•åˆ†æã€‘</b><br><br>"
                                image_result += "<br><br>".join(analysis_results)
                            return image_result
                        else:
                            analysis_results.append("ğŸ–¼ï¸ <b>å›¾ç‰‡ç”Ÿæˆ</b>ï¼šç”Ÿæˆå¤±è´¥ï¼ˆè¯·æŸ¥çœ‹ç»ˆç«¯é”™è¯¯ä¿¡æ¯ï¼‰")

            # 5. ç¿»è¯‘å¤„ç†ï¼ˆåŸæœ‰åŠŸèƒ½ï¼‰
            if enabled_models.get('translation', True):
                translation_result = cls._handle_translation(
                    sentence, category, cat_score, sentiment, sent_score, enabled_models
                )
                if translation_result:
                    if analysis_results:
                        translation_result += "<br><br>â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”<br><b>ã€æ‰©å±•åˆ†æã€‘</b><br><br>"
                        translation_result += "<br><br>".join(analysis_results)
                    return translation_result

            # 6. æ™ºèƒ½é—®ç­”ï¼ˆåŸæœ‰åŠŸèƒ½ï¼‰
            if enabled_models.get('qa', True):
                qa_response = cls._generate_response(
                    sentence, category, cat_score, sentiment, sent_score, enabled_models
                )
                if analysis_results:
                    qa_response += "<br><br>â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”<br><b>ã€æ‰©å±•åˆ†æã€‘</b><br><br>"
                    qa_response += "<br><br>".join(analysis_results)
                return qa_response
            else:
                # é—®ç­”ç¦ç”¨æ—¶è¿”å›åˆ†æç»“æœ
                if analysis_results or enabled_models.get('text_classification') or enabled_models.get('sentiment_analysis'):
                    result_text = "<b>ã€æ™ºèƒ½åˆ†æã€‘</b><br>"
                    if enabled_models.get('text_classification'):
                        result_text += f"ğŸ“Œ æ–‡æœ¬åˆ†ç±»ï¼š{category}ï¼ˆç½®ä¿¡åº¦ï¼š{cat_score:.2f}ï¼‰<br>"
                    if enabled_models.get('sentiment_analysis'):
                        result_text += f"â¤ï¸ æƒ…æ„Ÿå€¾å‘ï¼š{sentiment}ï¼ˆç½®ä¿¡åº¦ï¼š{sent_score:.2f}ï¼‰<br>"
                    if analysis_results:
                        result_text += "<br>â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”<br><b>ã€æ‰©å±•åˆ†æã€‘</b><br><br>"
                        result_text += "<br><br>".join(analysis_results)
                    return TextProcessor.format_text(result_text)
                else:
                    return TextProcessor.format_text("æ‰€æœ‰åŠŸèƒ½å·²ç¦ç”¨ï¼Œè¯·åœ¨å·¦ä¾§é¢æ¿å¯ç”¨è‡³å°‘ä¸€ä¸ªåŠŸèƒ½")

        except Exception as e:
            error_msg = f"å¤„ç†å¤±è´¥: {str(e)}"
            print(f"èŠå¤©æœåŠ¡é”™è¯¯: {error_msg}")
            return TextProcessor.format_text(error_msg)

    @classmethod
    def _classify_text(cls, text: str) -> Tuple[str, float]:
        state = SystemState()
        if not state.text_classification_available:
            return "æœªçŸ¥", 0.0
        try:
            from text_classification import predict_text_category
            paths = Config.get_model_paths()
            return predict_text_category(text=text, model_path=paths['text_category_model'], vocab_dir=paths['vocab_dir'])
        except Exception as e:
            print(f"æ–‡æœ¬åˆ†ç±»å¤±è´¥: {str(e)}")
            return "æœªçŸ¥", 0.0

    @classmethod
    def _analyze_sentiment(cls, text: str) -> Tuple[str, float]:
        state = SystemState()
        try:
            from emotion_analysis import predict_sentiment
            return predict_sentiment(text=text, dicts=state._sentiment_dicts, model=state._sentiment_model)
        except Exception as e:
            print(f"æƒ…æ„Ÿåˆ†æå¤±è´¥: {str(e)}")
            return "neutral", 0.5

    @classmethod
    def _handle_translation(cls, text: str, category: str, cat_score: float,
                            sentiment: str, sent_score: float, enabled_models: Dict) -> Optional[str]:
        state = SystemState()
        match = cls.TRANSLATION_PATTERN.search(text)
        if not match or not state.translation_loaded:
            return None
        try:
            from machine_translation import machine_translate
            translate_text = match.group(1) or match.group(3)
            translate_text = translate_text.strip() if translate_text else text
            if not translate_text:
                return TextProcessor.format_text("è¯·è¾“å…¥éœ€è¦ç¿»è¯‘çš„ä¸­æ–‡å†…å®¹")
            if translate_text[-1] not in TextProcessor.END_PUNCTS:
                translate_text += 'ã€‚'
            result = machine_translate(translate_text, src_lang="zh", tgt_lang="en")
            response = f"<b>ã€ä¸­è¯‘è‹±ç»“æœã€‘</b><br>{result}<br><br>"
            if enabled_models.get('text_classification') or enabled_models.get('sentiment_analysis'):
                response += "<b>ã€åŸºç¡€åˆ†æã€‘</b><br>"
                if enabled_models.get('text_classification'):
                    response += f"ğŸ“Œ æ–‡æœ¬åˆ†ç±»ï¼š{category}ï¼ˆç½®ä¿¡åº¦ï¼š{cat_score:.2f}ï¼‰<br>"
                if enabled_models.get('sentiment_analysis'):
                    response += f"â¤ï¸ æƒ…æ„Ÿå€¾å‘ï¼š{sentiment}ï¼ˆç½®ä¿¡åº¦ï¼š{sent_score:.2f}ï¼‰"
            return TextProcessor.format_text(response)
        except Exception as e:
            print(f"ç¿»è¯‘å¤±è´¥: {str(e)}")
            return TextProcessor.format_text(f"ç¿»è¯‘æœåŠ¡æš‚æ—¶ä¸å¯ç”¨<br>é”™è¯¯ï¼š{str(e)}")

    @classmethod
    def _generate_response(cls, text: str, category: str, cat_score: float,
                           sentiment: str, sent_score: float, enabled_models: Dict) -> str:
        sentiment_prompt = cls.SENTIMENT_PROMPTS.get(sentiment, "")
        category_prompt = f"ç”¨æˆ·é—®é¢˜å±äº{category}é¢†åŸŸï¼Œè¯·ä½¿ç”¨ç›¸å…³ä¸“ä¸šçŸ¥è¯†ï¼›"
        system_prompt = f"ä½ æ˜¯æ™ºèƒ½é—®ç­”åŠ©æ‰‹ï¼Œéµå¾ªä»¥ä¸‹è§„åˆ™ï¼š1. {sentiment_prompt}2. {category_prompt}3. å›å¤é•¿åº¦æ§åˆ¶åœ¨200å­—ä»¥å†…ï¼›4. æ— æ³•å›ç­”æ—¶ï¼Œå‹å¥½å‘ŠçŸ¥å¹¶å¼•å¯¼ã€‚"
        
        payload = json.dumps({
            "model": Config.ARK_MODEL,
            "messages": [{"role": "system", "content": system_prompt}, {"role": "user", "content": text}]
        })
        headers = {'Authorization': Config.ARK_AUTH_TOKEN, 'Content-Type': 'application/json'}
        
        try:
            conn = http.client.HTTPSConnection(Config.ARK_API_HOST)
            conn.request("POST", Config.ARK_API_PATH, payload, headers)
            response = conn.getresponse()
            data = response.read().decode("utf-8")
            conn.close()
            clean_data = TextProcessor.sanitize_text(data)
            reply = json.loads(clean_data)["choices"][0]["message"]["content"]
            
            response_text = f"<b>ã€æ™ºèƒ½å›ç­”ã€‘</b><br>{reply}<br><br>"
            if enabled_models.get('text_classification') or enabled_models.get('sentiment_analysis'):
                response_text += "<b>ã€åŸºç¡€åˆ†æã€‘</b><br>"
                if enabled_models.get('text_classification'):
                    response_text += f"ğŸ“Œ æ–‡æœ¬åˆ†ç±»ï¼š{category}ï¼ˆç½®ä¿¡åº¦ï¼š{cat_score:.2f}ï¼‰<br>"
                if enabled_models.get('sentiment_analysis'):
                    response_text += f"â¤ï¸ æƒ…æ„Ÿå€¾å‘ï¼š{sentiment}ï¼ˆç½®ä¿¡åº¦ï¼š{sent_score:.2f}ï¼‰"
            return TextProcessor.format_text(response_text)
        except Exception as e:
            raise Exception(f"APIè°ƒç”¨å¤±è´¥: {str(e)}")

# ========== Webåº”ç”¨ ==========
app = Flask(__name__, template_folder='templates', static_folder='static')

# å›¾ç‰‡ä¸Šä¼ æ¥å£ï¼ˆä¿®å¤ï¼šæ˜ç¡®æŒ‡å®šContent-Typeï¼Œå…¼å®¹form-dataå’Œjsonï¼‰
@app.route('/upload_image', methods=['POST'])
def upload_image():
    try:
        # ä¿®å¤ï¼šåŒæ—¶æ”¯æŒjsonå’Œform-dataæ ¼å¼
        if request.is_json:
            data = request.get_json()
        else:
            data = request.form.to_dict()
        
        file_data = data.get('file_data')
        filename = data.get('filename', 'unknown.png')
        enabled_models_str = data.get('models', '{}')
        
        try:
            enabled_models = json.loads(enabled_models_str)
        except:
            enabled_models = {k: True for k in SystemState()._enabled_models.keys()}
        
        if not enabled_models.get('image_upload', True):
            return jsonify({'status': 'error', 'message': 'å›¾ç‰‡ä¸Šä¼ åŠŸèƒ½å·²ç¦ç”¨'})
        if not file_data:
            return jsonify({'status': 'error', 'message': 'è¯·é€‰æ‹©å›¾ç‰‡'})
        
        image_path = ImageProcessor.upload_image(file_data, filename)
        if image_path:
            return jsonify({
                'status': 'success',
                'html': f"""ğŸ“¤ <b>å›¾ç‰‡ä¸Šä¼ æˆåŠŸ</b>
<br>â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
<br><img src="{image_path}" style="max-width:300px;border-radius:8px;margin-top:8px;">"""
            })
        else:
            return jsonify({'status': 'error', 'message': 'å›¾ç‰‡ä¸Šä¼ å¤±è´¥ï¼ˆæŸ¥çœ‹ç»ˆç«¯é”™è¯¯ï¼‰'})
    except Exception as e:
        print(f"ä¸Šä¼ æ¥å£é”™è¯¯ï¼š{str(e)}")
        return jsonify({'status': 'error', 'message': f'ä¸Šä¼ é”™è¯¯ï¼š{str(e)}'})

# æ¶ˆæ¯å¤„ç†æ¥å£ï¼ˆåŸæœ‰ï¼‰
@app.route('/message', methods=['POST'])
def handle_message():
    message = request.form.get('msg', '').strip()
    enabled_models_str = request.form.get('models', '{}')
    try:
        enabled_models = json.loads(enabled_models_str)
    except:
        enabled_models = {k: True for k in SystemState()._enabled_models.keys()}
    if not message:
        return jsonify({'text': TextProcessor.format_text('è¯·è¾“å…¥å†…å®¹ï½')})
    response = ChatService.process_message(message, enabled_models)
    response = response.replace('_UNK', '^_^').strip()
    return jsonify({'text': response if response else TextProcessor.format_text('æˆ‘ä»¬æ¥èŠèŠå¤©å§ï½')})

# æ¨¡å‹çŠ¶æ€æŸ¥è¯¢æ¥å£ï¼ˆåŸæœ‰+å›¾ç‰‡åŠŸèƒ½ï¼‰
@app.route('/get_model_status', methods=['GET'])
def get_model_status():
    state = SystemState()
    status = {
        'text_classification': {'enabled': state.is_model_enabled('text_classification'), 'available': state.text_classification_available},
        'sentiment_analysis': {'enabled': state.is_model_enabled('sentiment_analysis'), 'available': state._sentiment_model is not None},
        'translation': {'enabled': state.is_model_enabled('translation'), 'available': state.translation_loaded},
        'qa': {'enabled': state.is_model_enabled('qa'), 'available': True},
        'image_generate': {'enabled': state.is_model_enabled('image_generate'), 'available': True},
        'image_upload': {'enabled': state.is_model_enabled('image_upload'), 'available': True}
    }
    new_features = ['text_statistics', 'text_summary', 'word_frequency', 'language_detection', 'keyword_extraction', 'entity_recognition', 'deep_thinking']
    for feature in new_features:
        status[feature] = {'enabled': state.is_model_enabled(feature), 'available': NEW_MODULES_AVAILABLE}
    return jsonify(status)

# é¡µé¢è·¯ç”±ï¼ˆåŸæœ‰ï¼‰
@app.route("/")
def home():
    return render_template('html.html')

@app.route("/classic")
def classic():
    return render_template('index.html')

# ========== ä¸»ç¨‹åº ==========
if __name__ == '__main__':
    ModelManager.initialize_models()

    print("\n" + "=" * 50)
    print("ğŸš€ WebæœåŠ¡å·²å¯åŠ¨")
    print("=" * 50)
    print("å¢å¼ºç‰ˆç•Œé¢: http://127.0.0.1:8808")
    print("ç»å…¸ç‰ˆç•Œé¢: http://127.0.0.1:8808/classic")
    print("=" * 50)
    print("ğŸ“¦ åŠŸèƒ½åˆ—è¡¨ï¼š")
    print("  âœ“ æ ¸å¿ƒåŠŸèƒ½ï¼šæ–‡æœ¬åˆ†ç±»ã€æƒ…æ„Ÿåˆ†æã€æœºå™¨ç¿»è¯‘ã€æ™ºèƒ½é—®ç­”")
    print("  âœ“ æ–‡æœ¬åˆ†æï¼šæ–‡æœ¬ç»Ÿè®¡ã€æ–‡æœ¬æ‘˜è¦ã€è¯é¢‘åˆ†æã€è¯­è¨€æ£€æµ‹ã€å…³é”®è¯æå–ã€å®ä½“è¯†åˆ«ã€æ·±åº¦æ€è€ƒ")
    print("  âœ“ å›¾ç‰‡åŠŸèƒ½ï¼šç”Ÿæˆå›¾ç‰‡ï¼ˆç«å±±SDKï¼‰ã€æ·»åŠ å›¾ç‰‡ï¼ˆæœ¬åœ°ä¸Šä¼ ï¼‰")
    print("=" * 50)
    print("âœ¨ ä½¿ç”¨è¯´æ˜ï¼š")
    print("  - ç”Ÿæˆå›¾ç‰‡ï¼šè¾“å…¥'ç”Ÿæˆå›¾ç‰‡ï¼šå…³é”®è¯'ï¼ˆä¾‹ï¼šç”Ÿæˆå›¾ç‰‡ï¼šè“å¤©ç™½äº‘ï¼‰")
    print("  - æ·»åŠ å›¾ç‰‡ï¼šç‚¹å‡»'ä¸Šä¼ å›¾ç‰‡'æŒ‰é’®é€‰æ‹©æœ¬åœ°æ–‡ä»¶")
    print("  - é—®é¢˜æ’æŸ¥ï¼šæŸ¥çœ‹ç»ˆç«¯è¾“å‡ºçš„è¯¦ç»†é”™è¯¯ä¿¡æ¯")
    print("=" * 50 + "\n")

app.run(host='127.0.0.1', port=8808, debug=False)